{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec387f3a4794fcd813d9b690526efa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Modelo:', options=('Logistic Regression', 'Ridge Classifier', 'SGD Classi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bae90de3cf745488fb6bf0309835b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, RidgeClassifier, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \n",
    "    ExtraTreesClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "data_folder = \"dataset_matlab\"\n",
    "\n",
    "# Cargar conjuntos de datos\n",
    "X_train = pd.read_csv(f\"{data_folder}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"{data_folder}/y_train.csv\").values.ravel()\n",
    "X_test = pd.read_csv(f\"{data_folder}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"{data_folder}/y_test.csv\").values.ravel()\n",
    "\n",
    "# Definir los modelos disponibles\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"SGD Classifier\": SGDClassifier(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"Passive Aggressive\": PassiveAggressiveClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM (SVC)\": SVC(),\n",
    "    \"SVM (NuSVC)\": NuSVC(),\n",
    "    \"SVM (LinearSVC)\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Hist Gradient Boosting\": HistGradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME'),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"MLP (Neural Network)\": MLPClassifier()\n",
    "}\n",
    "\n",
    "# Definir el espacio de búsqueda para cada modelo (prefijado con 'model__')\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {'model__C': [0.1, 1, 10], 'model__solver': ['liblinear', 'saga']},\n",
    "    \"Ridge Classifier\": {'model__alpha': [0.1, 1, 10]},\n",
    "    \"SGD Classifier\": {'model__loss': ['hinge', 'log', 'squared_hinge'], 'model__alpha': [0.0001, 0.001, 0.01]},\n",
    "    \"Perceptron\": {'model__alpha': [0.0001, 0.001, 0.01], 'model__max_iter': [1000]},\n",
    "    \"Passive Aggressive\": {'model__C': [0.1, 1, 10], 'model__max_iter': [1000]},\n",
    "    \"KNN\": {'model__n_neighbors': [3, 5, 7, 9], 'model__metric': ['euclidean', 'manhattan']},\n",
    "    \"Decision Tree\": {'model__max_depth': [3, 5, 10], 'model__min_samples_split': [2, 5, 10]},\n",
    "    \"SVM (SVC)\": {'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf'], 'model__gamma': ['scale', 'auto']},\n",
    "    \"SVM (NuSVC)\": {'model__C': [0.1, 1, 10], 'model__nu': [0.1, 0.5, 0.9]},\n",
    "    \"SVM (LinearSVC)\": {'model__C': [0.1, 1, 10], 'model__loss': ['hinge', 'squared_hinge']},\n",
    "    \"Random Forest\": {'model__n_estimators': [50, 100, 200], 'model__max_depth': [3, 5, 10]},\n",
    "    \"Hist Gradient Boosting\": {'model__max_iter': [100, 200], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': [3, 5, 10]},\n",
    "    \"AdaBoost\": {'model__n_estimators': [50, 100, 200], 'model__learning_rate': [0.01, 0.1, 1]},\n",
    "    \"Extra Trees\": {'model__n_estimators': [50, 100, 200], 'model__max_depth': [3, 5, 10]},\n",
    "    \"Bagging\": {'model__n_estimators': [50, 100, 200], 'model__max_samples': [0.5, 0.75, 1.0]},\n",
    "    \"Gaussian Naive Bayes\": {},\n",
    "    \"Bernoulli Naive Bayes\": {},\n",
    "    \"Linear Discriminant Analysis\": {'model__solver': ['svd', 'lsqr', 'eigen']},\n",
    "    \"Quadratic Discriminant Analysis\": {'model__reg_param': [0.1, 1, 10]},\n",
    "    \"MLP (Neural Network)\": {'model__hidden_layer_sizes': [(50,), (100,), (50, 50)], 'model__activation': ['relu', 'tanh'], 'model__solver': ['adam', 'sgd']}\n",
    "}\n",
    "\n",
    "param_spaces = {\n",
    "    \"Logistic Regression\": {'model__C': Real(1e-3, 1e3, prior='log-uniform'), 'model__solver': Categorical(['liblinear', 'saga'])},\n",
    "    \"Ridge Classifier\": {'model__alpha': Real(1e-3, 1e3, prior='log-uniform')},\n",
    "    \"SGD Classifier\": {'model__loss': Categorical(['hinge', 'log', 'squared_hinge']), 'model__alpha': Real(1e-6, 1e-1, prior='log-uniform')},\n",
    "    \"Perceptron\": {'model__alpha': Real(1e-6, 1e-1, prior='log-uniform'), 'model__max_iter': Integer(500, 2000)},\n",
    "    \"Passive Aggressive\": {'model__C': Real(1e-3, 1e3, prior='log-uniform'), 'model__max_iter': Integer(500, 2000)},\n",
    "    \"KNN\": {'model__n_neighbors': Integer(1, 20), 'model__metric': Categorical(['euclidean', 'manhattan'])},\n",
    "    \"Decision Tree\": {'model__max_depth': Integer(2, 10), 'model__min_samples_split': Integer(2, 50), 'model__min_samples_leaf': Integer(1, 20), 'model__max_features': Categorical(['sqrt', 'log2', None]), 'model__criterion': Categorical(['gini', 'entropy'])},\n",
    "    \"SVM (SVC)\": {'model__C': Real(1e-3, 1e3, prior='log-uniform'), 'model__kernel': Categorical(['linear', 'rbf']), 'model__gamma': Real(1e-6, 1e1, prior='log-uniform')},\n",
    "    \"SVM (NuSVC)\": {'model__C': Real(1e-3, 1e3, prior='log-uniform'), 'model__nu': Real(0.1, 0.9)},\n",
    "    \"SVM (LinearSVC)\": {'model__C': Real(1e-3, 1e3, prior='log-uniform'), 'model__loss': Categorical(['hinge', 'squared_hinge'])},\n",
    "    \"Random Forest\": {'model__n_estimators': Integer(50, 500), 'model__max_depth': Integer(3, 50)},\n",
    "    \"Hist Gradient Boosting\": {'model__max_iter': Integer(50, 500), 'model__learning_rate': Real(1e-3, 1, prior='log-uniform'), 'model__max_depth': Integer(3, 50)},\n",
    "    \"AdaBoost\": {'model__n_estimators': Integer(50, 500), 'model__learning_rate': Real(1e-3, 1, prior='log-uniform')},\n",
    "    \"Extra Trees\": {'model__n_estimators': Integer(50, 500), 'model__max_depth': Integer(3, 50)},\n",
    "    \"Bagging\": {'model__n_estimators': Integer(50, 500), 'model__max_samples': Real(0.1, 1.0)},\n",
    "    \"Gaussian Naive Bayes\": {},\n",
    "    \"Bernoulli Naive Bayes\": {},\n",
    "    \"Linear Discriminant Analysis\": {'model__solver': Categorical(['svd', 'lsqr', 'eigen'])},\n",
    "    \"Quadratic Discriminant Analysis\": {'model__reg_param': Real(1e-3, 1e1, prior='log-uniform')},\n",
    "    \"MLP (Neural Network)\": {'model__hidden_layer_sizes': Categorical([(50,), (100,), (50, 50)]), 'model__activation': Categorical(['relu', 'tanh']), 'model__solver': Categorical(['adam', 'sgd'])}\n",
    "}\n",
    "\n",
    "# Función para optimización con GridSearch, RandomizedSearch o Bayesian\n",
    "def optimize_model(model_name, optimization_mode):\n",
    "    model = models[model_name]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    ('smote', SMOTE()),  # Se aplica solo a X_train en cada fold\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('model', model)  # Modelo de clasificación\n",
    "    ])\n",
    "    \n",
    "    if optimization_mode == 'Grid Search':\n",
    "        param_grid = param_grids[model_name]\n",
    "        search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    \n",
    "    elif optimization_mode == 'Random Search':\n",
    "        param_dist = param_grids[model_name]\n",
    "        search = RandomizedSearchCV(pipeline, param_dist, cv=5, n_iter=30)\n",
    "    \n",
    "    elif optimization_mode == 'Bayesian Optimization':\n",
    "        param_space = param_spaces[model_name]\n",
    "        search = BayesSearchCV(pipeline, param_space, n_iter=30, cv=5)\n",
    "    \n",
    "    # Ajustar el modelo con los parámetros optimizados\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    # Evaluación\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mejor modelo ({optimization_mode}) para {model_name}:\\n\", best_model)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Crear interfaz interactiva con ipywidgets\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=models.keys(),\n",
    "    description='Modelo:'\n",
    ")\n",
    "\n",
    "optimization_selector = widgets.Dropdown(\n",
    "    options=['Grid Search', 'Random Search', 'Bayesian Optimization'],\n",
    "    description='Optimización:',\n",
    "    value='Grid Search'\n",
    ")\n",
    "\n",
    "# Crear un botón para ejecutar la optimización\n",
    "execute_button = widgets.Button(description=\"Ejecutar Optimización\")\n",
    "\n",
    "# Salida para mostrar los resultados\n",
    "out = widgets.Output()\n",
    "\n",
    "# Función que se ejecutará cuando se presione el botón\n",
    "def on_button_click(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        model_name = model_selector.value\n",
    "        optimization_mode = optimization_selector.value\n",
    "        print(\"Ejecutando optimización...\\n\")\n",
    "        optimize_model(model_name, optimization_mode)\n",
    "\n",
    "# Asocia el botón con la función\n",
    "execute_button.on_click(on_button_click)\n",
    "\n",
    "# Interfaz de usuario con el botón\n",
    "ui = widgets.VBox([model_selector, optimization_selector, execute_button])\n",
    "\n",
    "# Mostrar la interfaz y la salida\n",
    "display(ui, out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
