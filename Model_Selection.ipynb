{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@ebimsv/ml-series-day-42-statistical-tests-for-model-comparison-4f5cf63da74a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a701cfcf33247b896ace10ecdb6a99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model 1', options=('Logistic Regression', 'Ridge Classifier', 'SGD Classifier', 'Percept…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d8e7e47afa46c79b58a2defb41dd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model 2', options=('Logistic Regression', 'Ridge Classifier', 'SGD Classifier', 'Percept…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be85feeb5e9b4610a854eb9ebb22b43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Evaluation', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9d3ca4620c4172a6886c40c8da8c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Output\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from math import log\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, RidgeClassifier, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \n",
    "    ExtraTreesClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Cargar los conjuntos de datos desde archivos CSV\n",
    "X = pd.read_csv(\"datasets/X_train.csv\")\n",
    "y = pd.read_csv(\"datasets/y_train.csv\").values.ravel()\n",
    "\n",
    "\n",
    "# Lista de modelos disponibles\n",
    "model_options = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"SGD Classifier\": SGDClassifier(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"Passive Aggressive\": PassiveAggressiveClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM (SVC)\": SVC(),\n",
    "    \"SVM (NuSVC)\": NuSVC(),\n",
    "    \"SVM (LinearSVC)\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    #\"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Hist Gradient Boosting\": HistGradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"MLP (Neural Network)\": MLPClassifier()\n",
    "}\n",
    "\n",
    "# Crear widgets para selección de modelos\n",
    "model_1_selector = widgets.Dropdown(options=list(model_options.keys()), description=\"Model 1\")\n",
    "model_2_selector = widgets.Dropdown(options=list(model_options.keys()), description=\"Model 2\")\n",
    "run_button = widgets.Button(description=\"Run Evaluation\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_pipeline(model):\n",
    "    return make_pipeline(StandardScaler(), model)\n",
    "\n",
    "def evaluate_models(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        model_1 = model_options[model_1_selector.value]\n",
    "        model_2 = model_options[model_2_selector.value]\n",
    "        \n",
    "        # Calcular precisión con validación cruzada\n",
    "        acc_model_1 = cross_val_score(get_pipeline(model_1), X, y, cv=5, scoring='accuracy')\n",
    "        acc_model_2 = cross_val_score(get_pipeline(model_2), X, y, cv=5, scoring='accuracy')\n",
    "        print(f\"Cross-Validated Accuracy Model 1 ({model_1_selector.value}): {acc_model_1.mean()}\")\n",
    "        print(f\"Cross-Validated Accuracy Model 2 ({model_2_selector.value}): {acc_model_2.mean()}\")\n",
    "        \n",
    "        # Prueba estadística (t-test)\n",
    "        t_stat, p_value = stats.ttest_rel(acc_model_1, acc_model_2)\n",
    "        print(f\"T-Statistic: {t_stat}\")\n",
    "        print(f\"P-Value: {p_value}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"We reject the null hypothesis: The difference in performance is statistically significant.\")\n",
    "        else:\n",
    "            print(\"We fail to reject the null hypothesis: The difference in performance is not statistically significant.\")\n",
    "        \n",
    "        # Calcular AIC y BIC\n",
    "        log_likelihood_model_1 = -log(acc_model_1.mean())\n",
    "        log_likelihood_model_2 = -log(acc_model_2.mean())\n",
    "        n = len(y)\n",
    "        k_model_1 = 1  # Se usa un valor por defecto para simplificar\n",
    "        k_model_2 = 1\n",
    "        \n",
    "        aic_1 = 2*k_model_1 - 2*log_likelihood_model_1\n",
    "        bic_1 = np.log(n)*k_model_1 - 2*log_likelihood_model_1\n",
    "        aic_2 = 2*k_model_2 - 2*log_likelihood_model_2\n",
    "        bic_2 = np.log(n)*k_model_2 - 2*log_likelihood_model_2\n",
    "        \n",
    "        print(f\"AIC Model 1 ({model_1_selector.value}): {aic_1}\")\n",
    "        print(f\"BIC Model 1 ({model_1_selector.value}): {bic_1}\")\n",
    "        print(f\"AIC Model 2 ({model_2_selector.value}): {aic_2}\")\n",
    "        print(f\"BIC Model 2 ({model_2_selector.value}): {bic_2}\")\n",
    "\n",
    "run_button.on_click(evaluate_models)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(model_1_selector, model_2_selector, run_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
